# Example Agent Configuration
# This file demonstrates per-workspace configuration options that override global defaults.
# Copy this file to your workspace directory and customize as needed.

# Agent identity (optional, for documentation)
name: Example Assistant
description: A helpful AI assistant for demonstrations

# LLM Model Configuration
model:
  # Model provider: anthropic, openai, etc.
  provider: anthropic

  # Model identifier (provider-specific)
  # Examples:
  #   - claude-sonnet-4-20250514
  #   - claude-opus-4-5-20251101
  #   - gpt-4
  model: claude-sonnet-4-20250514

  # API key for the model provider (use environment variable substitution)
  # Pattern: ${VARIABLE_NAME} will be replaced with os.environ.get("VARIABLE_NAME")
  api_key: ${ANTHROPIC_API_KEY}

  # Sampling temperature (0.0 = deterministic, 1.0 = creative)
  # Lower values make responses more focused and consistent
  temperature: 0.7

  # Maximum conversation turns before forcing termination
  max_turns: 50

# Channel Binding Configuration
channel:
  # Channel type: telegram, slack, discord, etc.
  type: telegram

  # Channel-specific authentication token
  token: ${TELEGRAM_BOT_TOKEN}

  # Allowed user IDs (empty list = all users allowed)
  # Get user IDs from Telegram by messaging the bot and checking logs
  allowed_users: []

  # Allowed group/chat IDs (empty list = all groups allowed)
  allowed_groups: []

# Queue Behavior Overrides
queue:
  # Queue mode determines message handling:
  #   - collect: Buffer messages during agent runs, process together
  #   - steer: Interrupt current run with new messages
  #   - followup: Queue messages for sequential processing
  mode: collect

  # Debounce delay in milliseconds before processing queued messages
  # Higher values reduce interruptions but increase response latency
  debounce_ms: 1000
